import os
import streamlit as st
import warnings

# è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings("ignore")

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # dotenvãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
    pass

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIå°‚é–€å®¶ãƒãƒ£ãƒƒãƒˆ",
    page_icon="ğŸ¤–",
    layout="centered"
)

st.title("ğŸ¤– AIå°‚é–€å®¶ãƒãƒ£ãƒƒãƒˆ")
st.markdown("å°‚é–€åˆ†é‡ã‚’é¸æŠã—ã¦ã€AIã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¨å¯¾è©±ã§ãã¾ã™ã€‚")

user_input = st.text_input(label="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", placeholder="ã“ã“ã«è³ªå•ã‚’å…¥åŠ›...")

# LLMå¿œç­”é–¢æ•°ã®å®šç¾©
def get_llm_response(input_text, expert_type):
    try:
        from langchain_openai import ChatOpenAI
        from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
    except ImportError as e:
        return f"å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“: {str(e)}"
    
    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return "ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    
    if expert_type == "æ³•å¾‹":
        system_message = "ã‚ãªãŸã¯æ³•å¾‹ã®å°‚é–€å®¶ã§ã™ã€‚æ³•å¾‹ã«é–¢ã™ã‚‹è³ªå•ã«å¯¾ã—ã¦ã€æ­£ç¢ºã‹ã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
    elif expert_type == "AI":
        system_message = "ã‚ãªãŸã¯AIã®å°‚é–€å®¶ã§ã™ã€‚AIã«é–¢ã™ã‚‹è³ªå•ã«å¯¾ã—ã¦ã€æ­£ç¢ºã‹ã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
    else:
        system_message = "ã‚ãªãŸã¯å¥åº·ã®å°‚é–€å®¶ã§ã™ã€‚å¥åº·ã«é–¢ã™ã‚‹è³ªå•ã«å¯¾ã—ã¦ã€æ­£ç¢ºã‹ã¤ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"

    try:
        chat_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_message),
            HumanMessagePromptTemplate.from_template("{input_text}")
        ])

        messages = chat_prompt.format_messages(input_text=input_text)

        chat = ChatOpenAI(model="gpt-4o-mini", temperature=0.5)
        response = chat.invoke(messages)

        return response.content
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
    

expert_type = st.radio(
    "å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
    ["æ³•å¾‹", "AI", "å¥åº·"]
)

if st.button("å®Ÿè¡Œ"):
    if user_input.strip():
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            response = get_llm_response(user_input, expert_type)
            st.success("å›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼")
            st.write(response)
    else:
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")


